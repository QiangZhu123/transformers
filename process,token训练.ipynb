{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba7c7e5",
   "metadata": {},
   "source": [
    "# Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599027bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.image_processing_utils import BaseImageProcessor,BatchFeature\n",
    "from datasets import load_dataset\n",
    "from transformers.processing_utils import ProcessorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ea3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV1ImageProcessor(BaseImageProcessor):\n",
    "    model_input_names = [\"pixel_values\"]\n",
    "    \n",
    "    \"\"\"\n",
    "    只处理图片\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def resize(self):\n",
    "        return \n",
    "    def preprocess(self，images，**kwargs):\n",
    "        \"\"\"\n",
    "        数据transforms只需要是处理PIL格式的函数即可，在这里实现数据的类型和通道的调整,\n",
    "        如果要用mmpretrain中的增益方法，输入必须是{'img':img}的格式，需要加一个字符串映射\n",
    "        images (`ImageInput`): PIL\n",
    "        Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If\n",
    "        passing in images with pixel values between 0 and 1, set `do_rescale=False`.\n",
    "        #基类的__call__就是调用这个函数，images可以是一个，也可以是个batch，PIL--》np.array\n",
    "        可选操作包括\n",
    "        do_resize\n",
    "        do_center_crop\n",
    "        do_rescale\n",
    "        do_normalize\n",
    "        最后含有Totensor()的操作\n",
    "        \"\"\"\n",
    "        \n",
    "        data = {\"pixel_values\": images}#这里只有图片的输出\n",
    "        return BatchFeature(data=data, tensor_type=return_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignProcessor(ProcessorMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "    同时处理图片和文本的处理器\n",
    "    \"\"\"\n",
    "    attributes = [\"image_processor\", \"tokenizer\"]\n",
    "    image_processor_class = \"EfficientNetImageProcessor\"\n",
    "    tokenizer_class = (\"BertTokenizer\", \"BertTokenizerFast\")\n",
    "    \n",
    "    def __init__(self, image_processor=None, tokenizer=None):\n",
    "        super().__init__(image_processor, tokenizer)\n",
    "        \n",
    "    def __call__(self, text=None, images=None,\n",
    "                 padding=\"max_length\",\n",
    "                 max_length=64,\n",
    "                 return_tensors=None, **kwargs):\n",
    "        if text is None and images is None:\n",
    "            raise ValueError(\"You have to specify either text or images. Both cannot be none.\")\n",
    "\n",
    "        if text is not None:\n",
    "            encoding = self.tokenizer(\n",
    "                text, padding=padding, max_length=max_length, return_tensors=return_tensors, **kwargs\n",
    "            )\n",
    "\n",
    "        if images is not None:\n",
    "            image_features = self.image_processor(images, return_tensors=return_tensors, **kwargs)\n",
    "\n",
    "        if text is not None and images is not None:\n",
    "            encoding[\"pixel_values\"] = image_features.pixel_values\n",
    "            return encoding\n",
    "        elif text is not None:\n",
    "            return encoding\n",
    "        else:\n",
    "            #这个类只要是根据return_tensors来确定是否对输入转化成张量的操作类\n",
    "            return BatchEncoding(data=dict(**image_features), tensor_type=return_tensors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce33636",
   "metadata": {},
   "source": [
    "# Tokener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "#映射token\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374090a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "new_tokenizer = tokenizer.train_new_from_iterator(batch_iterator(), vocab_size=25000)\n",
    "#使用\n",
    "new_tokenizer(dataset[:5][\"text\"])\n",
    "\n",
    "#保存\n",
    "new_tokenizer.save_pretrained(\"my-new-tokenizer\")\n",
    "#载入\n",
    "tok = new_tokenizer.from_pretrained(\"my-new-tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514eef9",
   "metadata": {},
   "source": [
    "# 从头训练一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6bb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Byte-Pair Encoding (BPE), WordPiece, and SentencePiece三种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93597fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(models.WordPiece(unl_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm部分\n",
    "tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\n",
    "#预先定义部分\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练方式比较特殊，要一个特殊的trainer\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3de853",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode(\"This is one sentence.\", \"With this one we have a pair.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0928ba8",
   "metadata": {},
   "source": [
    "# 完整实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"This is an example!\")\n",
    "trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=[\"<|endoftext|>\"])\n",
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24166440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "new_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ccf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.tokenize(\"I have a new GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c26e34",
   "metadata": {},
   "source": [
    "# 视频图片处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbfdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    对视频进行采样取祯\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    '''\n",
    "    生成采样的序列号\n",
    "    '''\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    end_idx = np.random.randint(converted_len, seg_len)\n",
    "    start_idx = end_idx - converted_len\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
    "file_path = hf_hub_download(\n",
    "    repo_id=\"nielsr/video-demo\", filename=\"eating_spaghetti.mp4\", repo_type=\"dataset\"\n",
    ")\n",
    "container = av.open(file_path)\n",
    "\n",
    "# sample 32 frames\n",
    "indices = sample_frame_indices(clip_len=32, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\n",
    "#输出就是一个张量\n",
    "video = read_video_pyav(container=container, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = VivitImageProcessor.from_pretrained(\"google/vivit-b-16x2-kinetics400\")\n",
    "# prepare video for the model\n",
    "inputs = image_processor(list(video), return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb2329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db9412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
